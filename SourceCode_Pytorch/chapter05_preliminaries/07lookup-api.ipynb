{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# 查阅文档\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "由于本书篇幅限制，我们不可能介绍每一个PyTorch函数和类（你可能也不希望我们这样做）。\n",
    "API文档、其他教程和示例提供了本书之外的大量文档。\n",
    "在本节中，我们为你提供了一些查看PyTorch API的指导。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 4
   },
   "source": [
    "## 查找模块中的所有函数和类\n",
    "\n",
    "为了知道模块中可以调用哪些函数和类，我们调用`dir`函数。\n",
    "例如，我们可以(**查询随机数生成模块中的所有属性：**)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "1"
    },
    "origin_pos": 6,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AbsTransform', 'AffineTransform', 'Bernoulli', 'Beta', 'Binomial', 'CatTransform', 'Categorical', 'Cauchy', 'Chi2', 'ComposeTransform', 'ContinuousBernoulli', 'CorrCholeskyTransform', 'Dirichlet', 'Distribution', 'ExpTransform', 'Exponential', 'ExponentialFamily', 'FisherSnedecor', 'Gamma', 'Geometric', 'Gumbel', 'HalfCauchy', 'HalfNormal', 'Independent', 'IndependentTransform', 'Kumaraswamy', 'LKJCholesky', 'Laplace', 'LogNormal', 'LogisticNormal', 'LowRankMultivariateNormal', 'LowerCholeskyTransform', 'MixtureSameFamily', 'Multinomial', 'MultivariateNormal', 'NegativeBinomial', 'Normal', 'OneHotCategorical', 'OneHotCategoricalStraightThrough', 'Pareto', 'Poisson', 'PowerTransform', 'RelaxedBernoulli', 'RelaxedOneHotCategorical', 'ReshapeTransform', 'SigmoidTransform', 'SoftmaxTransform', 'StackTransform', 'StickBreakingTransform', 'StudentT', 'TanhTransform', 'Transform', 'TransformedDistribution', 'Uniform', 'VonMises', 'Weibull', 'Wishart', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'bernoulli', 'beta', 'biject_to', 'binomial', 'categorical', 'cauchy', 'chi2', 'constraint_registry', 'constraints', 'continuous_bernoulli', 'dirichlet', 'distribution', 'exp_family', 'exponential', 'fishersnedecor', 'gamma', 'geometric', 'gumbel', 'half_cauchy', 'half_normal', 'identity_transform', 'independent', 'kl', 'kl_divergence', 'kumaraswamy', 'laplace', 'lkj_cholesky', 'log_normal', 'logistic_normal', 'lowrank_multivariate_normal', 'mixture_same_family', 'multinomial', 'multivariate_normal', 'negative_binomial', 'normal', 'one_hot_categorical', 'pareto', 'poisson', 'register_kl', 'relaxed_bernoulli', 'relaxed_categorical', 'studentT', 'transform_to', 'transformed_distribution', 'transforms', 'uniform', 'utils', 'von_mises', 'weibull', 'wishart']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(dir(torch.distributions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 8
   },
   "source": [
    "通常，我们可以忽略以“`__`”（双下划线）开始和结束的函数（它们是Python中的特殊对象），\n",
    "或以单个“`_`”（单下划线）开始的函数（它们通常是内部函数）。\n",
    "根据剩余的函数名或属性名，我们可能会猜测这个模块提供了各种生成随机数的方法，\n",
    "包括从均匀分布（`uniform`）、正态分布（`normal`）和多项分布（`multinomial`）中采样。\n",
    "\n",
    "## 查找特定函数和类的用法\n",
    "\n",
    "有关如何使用给定函数或类的更具体说明，我们可以调用`help`函数。\n",
    "例如，我们来[**查看张量`ones`函数的用法。**]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "origin_pos": 10,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function ones:\n",
      "\n",
      "ones(...)\n",
      "    ones(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n",
      "    \n",
      "    Returns a tensor filled with the scalar value `1`, with the shape defined\n",
      "    by the variable argument :attr:`size`.\n",
      "    \n",
      "    Args:\n",
      "        size (int...): a sequence of integers defining the shape of the output tensor.\n",
      "            Can be a variable number of arguments or a collection like a list or tuple.\n",
      "    \n",
      "    Keyword arguments:\n",
      "        out (Tensor, optional): the output tensor.\n",
      "        dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "            Default: if ``None``, uses a global default (see :func:`torch.set_default_tensor_type`).\n",
      "        layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.\n",
      "            Default: ``torch.strided``.\n",
      "        device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "            Default: if ``None``, uses the current device for the default tensor type\n",
      "            (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n",
      "            for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
      "        requires_grad (bool, optional): If autograd should record operations on the\n",
      "            returned tensor. Default: ``False``.\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> torch.ones(2, 3)\n",
      "        tensor([[ 1.,  1.,  1.],\n",
      "                [ 1.,  1.,  1.]])\n",
      "    \n",
      "        >>> torch.ones(5)\n",
      "        tensor([ 1.,  1.,  1.,  1.,  1.])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.ones)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 12
   },
   "source": [
    "从文档中，我们可以看到`ones`函数创建一个具有指定形状的新张量，并将所有元素值设置为1。\n",
    "让我们来[**运行一个快速测试**]来确认这一解释：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "origin_pos": 14,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Multinomial in module torch.distributions.multinomial:\n",
      "\n",
      "class Multinomial(torch.distributions.distribution.Distribution)\n",
      " |  Multinomial(total_count=1, probs=None, logits=None, validate_args=None)\n",
      " |  \n",
      " |  Creates a Multinomial distribution parameterized by :attr:`total_count` and\n",
      " |  either :attr:`probs` or :attr:`logits` (but not both). The innermost dimension of\n",
      " |  :attr:`probs` indexes over categories. All other dimensions index over batches.\n",
      " |  \n",
      " |  Note that :attr:`total_count` need not be specified if only :meth:`log_prob` is\n",
      " |  called (see example below)\n",
      " |  \n",
      " |  .. note:: The `probs` argument must be non-negative, finite and have a non-zero sum,\n",
      " |            and it will be normalized to sum to 1 along the last dimension. :attr:`probs`\n",
      " |            will return this normalized value.\n",
      " |            The `logits` argument will be interpreted as unnormalized log probabilities\n",
      " |            and can therefore be any real number. It will likewise be normalized so that\n",
      " |            the resulting probabilities sum to 1 along the last dimension. :attr:`logits`\n",
      " |            will return this normalized value.\n",
      " |  \n",
      " |  -   :meth:`sample` requires a single shared `total_count` for all\n",
      " |      parameters and samples.\n",
      " |  -   :meth:`log_prob` allows different `total_count` for each parameter and\n",
      " |      sample.\n",
      " |  \n",
      " |  Example::\n",
      " |  \n",
      " |      >>> m = Multinomial(100, torch.tensor([ 1., 1., 1., 1.]))\n",
      " |      >>> x = m.sample()  # equal probability of 0, 1, 2, 3\n",
      " |      tensor([ 21.,  24.,  30.,  25.])\n",
      " |  \n",
      " |      >>> Multinomial(probs=torch.tensor([1., 1., 1., 1.])).log_prob(x)\n",
      " |      tensor([-4.1338])\n",
      " |  \n",
      " |  Args:\n",
      " |      total_count (int): number of trials\n",
      " |      probs (Tensor): event probabilities\n",
      " |      logits (Tensor): event log probabilities (unnormalized)\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Multinomial\n",
      " |      torch.distributions.distribution.Distribution\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, total_count=1, probs=None, logits=None, validate_args=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  entropy(self)\n",
      " |      Returns entropy of distribution, batched over batch_shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Tensor of shape batch_shape.\n",
      " |  \n",
      " |  expand(self, batch_shape, _instance=None)\n",
      " |      Returns a new distribution instance (or populates an existing instance\n",
      " |      provided by a derived class) with batch dimensions expanded to\n",
      " |      `batch_shape`. This method calls :class:`~torch.Tensor.expand` on\n",
      " |      the distribution's parameters. As such, this does not allocate new\n",
      " |      memory for the expanded distribution instance. Additionally,\n",
      " |      this does not repeat any args checking or parameter broadcasting in\n",
      " |      `__init__.py`, when an instance is first created.\n",
      " |      \n",
      " |      Args:\n",
      " |          batch_shape (torch.Size): the desired expanded size.\n",
      " |          _instance: new instance provided by subclasses that\n",
      " |              need to override `.expand`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          New distribution instance with batch dimensions expanded to\n",
      " |          `batch_size`.\n",
      " |  \n",
      " |  log_prob(self, value)\n",
      " |      Returns the log of the probability density/mass function evaluated at\n",
      " |      `value`.\n",
      " |      \n",
      " |      Args:\n",
      " |          value (Tensor):\n",
      " |  \n",
      " |  sample(self, sample_shape=torch.Size([]))\n",
      " |      Generates a sample_shape shaped sample or sample_shape shaped batch of\n",
      " |      samples if the distribution parameters are batched.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  logits\n",
      " |  \n",
      " |  mean\n",
      " |      Returns the mean of the distribution.\n",
      " |  \n",
      " |  param_shape\n",
      " |  \n",
      " |  probs\n",
      " |  \n",
      " |  support\n",
      " |      Returns a :class:`~torch.distributions.constraints.Constraint` object\n",
      " |      representing this distribution's support.\n",
      " |  \n",
      " |  variance\n",
      " |      Returns the variance of the distribution.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {'total_count': <class 'int'>}\n",
      " |  \n",
      " |  arg_constraints = {'logits': IndependentConstraint(Real(), 1), 'probs'...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.distributions.distribution.Distribution:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  cdf(self, value)\n",
      " |      Returns the cumulative density/mass function evaluated at\n",
      " |      `value`.\n",
      " |      \n",
      " |      Args:\n",
      " |          value (Tensor):\n",
      " |  \n",
      " |  enumerate_support(self, expand=True)\n",
      " |      Returns tensor containing all values supported by a discrete\n",
      " |      distribution. The result will enumerate over dimension 0, so the shape\n",
      " |      of the result will be `(cardinality,) + batch_shape + event_shape`\n",
      " |      (where `event_shape = ()` for univariate distributions).\n",
      " |      \n",
      " |      Note that this enumerates over all batched tensors in lock-step\n",
      " |      `[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens\n",
      " |      along dim 0, but with the remaining batch dimensions being\n",
      " |      singleton dimensions, `[[0], [1], ..`.\n",
      " |      \n",
      " |      To iterate over the full Cartesian product use\n",
      " |      `itertools.product(m.enumerate_support())`.\n",
      " |      \n",
      " |      Args:\n",
      " |          expand (bool): whether to expand the support over the\n",
      " |              batch dims to match the distribution's `batch_shape`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Tensor iterating over dimension 0.\n",
      " |  \n",
      " |  icdf(self, value)\n",
      " |      Returns the inverse cumulative density/mass function evaluated at\n",
      " |      `value`.\n",
      " |      \n",
      " |      Args:\n",
      " |          value (Tensor):\n",
      " |  \n",
      " |  perplexity(self)\n",
      " |      Returns perplexity of distribution, batched over batch_shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Tensor of shape batch_shape.\n",
      " |  \n",
      " |  rsample(self, sample_shape=torch.Size([]))\n",
      " |      Generates a sample_shape shaped reparameterized sample or sample_shape\n",
      " |      shaped batch of reparameterized samples if the distribution parameters\n",
      " |      are batched.\n",
      " |  \n",
      " |  sample_n(self, n)\n",
      " |      Generates n samples or n batches of samples if the distribution\n",
      " |      parameters are batched.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from torch.distributions.distribution.Distribution:\n",
      " |  \n",
      " |  set_default_validate_args(value)\n",
      " |      Sets whether validation is enabled or disabled.\n",
      " |      \n",
      " |      The default behavior mimics Python's ``assert`` statement: validation\n",
      " |      is on by default, but is disabled if Python is run in optimized mode\n",
      " |      (via ``python -O``). Validation may be expensive, so you may want to\n",
      " |      disable it once a model is working.\n",
      " |      \n",
      " |      Args:\n",
      " |          value (bool): Whether to enable validation.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.distributions.distribution.Distribution:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  batch_shape\n",
      " |      Returns the shape over which parameters are batched.\n",
      " |  \n",
      " |  event_shape\n",
      " |      Returns the shape of a single sample (without batching).\n",
      " |  \n",
      " |  stddev\n",
      " |      Returns the standard deviation of the distribution.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from torch.distributions.distribution.Distribution:\n",
      " |  \n",
      " |  has_enumerate_support = False\n",
      " |  \n",
      " |  has_rsample = False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.distributions.multinomial.Multinomial)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 16
   },
   "source": [
    "在Jupyter记事本中，我们可以使用`?`指令在另一个浏览器窗口中显示文档。\n",
    "例如，`list?`指令将创建与`help(list)`指令几乎相同的内容，并在新的浏览器窗口中显示它。\n",
    "此外，如果我们使用两个问号，如`list??`，将显示实现该函数的Python代码。\n",
    "\n",
    "## 小结\n",
    "\n",
    "* 官方文档提供了本书之外的大量描述和示例。\n",
    "* 我们可以通过调用`dir`和`help`函数或在Jupyter记事本中使用`?`和`??`查看API的用法文档。\n",
    "\n",
    "## 练习\n",
    "\n",
    "1. 在深度学习框架中查找任何函数或类的文档。你能在这个框架的官方网站上找到文档吗?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 18,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[Discussions](https://discuss.d2l.ai/t/1765)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 ('d2l')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "fd0464672f31e473c271463035f93585a172b3a2c13123cd84164aecdfb66c5b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
